---
title: "LASSO Regression"
format: html
editor: visual
---

## LASSO Regression

## Background

LASSO (Least Absolute Shrinkage and Selection Operator) regression is a type of regression that shrinks the coefficients of the base linear regression model. It has the effect of forcing some of the coefficient estimates to be exactly zero, or produces sparse models. Thus, LASSO performs variable selection. This is well suited for when there is strong correlations between two or more predictor variables, known as multicollinearity, which creates redundant and skewed information in a regression model.

```{r}
library(dplyr)
library(glmnet)
library(caret)
library(tidyverse)
library(tidymodels)
```

The package we will be working with for LASSO regression is glmnet. There are some requirements for data formatting for this package. This means that our response variable will have to be in a vector and the predictor variables will have to be in matrix form

```{r}
# for reproducibility
set.seed(12)

# partition data
partitions <- life_clean %>%
  initial_split(prop = 0.8)

# Training Set
train_x <- training(partitions) %>%
  select(-Life.expectancy) %>%
  as.matrix()
train_y <- training(partitions) %>%
  pull(Life.expectancy)

# Testing Set
test_x <- testing(partitions) %>%
  select(-Life.expectancy) %>%
  as.matrix()
test_y <- testing(partitions) %>%
  pull(Life.expectancy)

```

Lambda is our tuning parameter for LASSO regression. We will find the optimal lambda value through cross validation.

```{r}
# lambda values we will choose from
lambdas <- 10^seq(2, -3, by = -.1)

# Perform cross validation to find best value of lambda
lasso_reg <- cv.glmnet(train_x, train_y, alpha = 1, lambda = lambdas)

# Best lambda value
best_lambda <- lasso_reg$lambda.min

best_lambda
```

We now fit the model by specifying the optimal lambda, and alpha = 1 which corresponds to LASSO regression.

```{r}
lasso_model <- glmnet(train_x, train_y, alpha = 1, lambda = best_lambda, standardize = TRUE)
```
